{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Credit Card Fraud Detection Demo\n",
        "\n",
        "This notebook walks through:\n",
        "- Downloading the dataset from Kaggle\n",
        "- Loading and splitting the dataset\n",
        "- Training multiple models\n",
        "- Evaluating performance with imbalance-aware metrics\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading dataset from Kaggle using kagglehub...\n",
            "KaggleHub failed: module 'kagglehub' has no attribute 'dataset_download'\n",
            "Please download creditcard.csv manually from https://www.kaggle.com/mlg-ulb/creditcardfraud\n",
            "and place it in the ../data/ directory\n",
            "Using existing dataset file\n",
            "Dataset saved to ../data/creditcard.csv\n",
            "Dataset shape: (284807, 31)\n",
            "Fraud cases: 492\n",
            "Non-fraud cases: 284315\n"
          ]
        }
      ],
      "source": [
        "# Install and import dependencies\n",
        "# !pip install kagglehub[pandas-datasets]  # Uncomment if not installed\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Import from src directory\n",
        "import sys\n",
        "sys.path.append('../src')\n",
        "\n",
        "from data_utils import load_creditcard_data\n",
        "from models import build_models\n",
        "from evaluation import evaluate_predictions, print_detailed_report\n",
        "\n",
        "# Option 1: Use KaggleHub (if working)\n",
        "try:\n",
        "    import kagglehub\n",
        "    print(\"Downloading dataset from Kaggle using kagglehub...\")\n",
        "    # Download the dataset\n",
        "    path = kagglehub.dataset_download(\"mlg-ulb/creditcardfraud\")\n",
        "    csv_file = os.path.join(path, \"creditcard.csv\")\n",
        "    df = pd.read_csv(csv_file)\n",
        "    print(\"Dataset loaded successfully from KaggleHub\")\n",
        "except Exception as e:\n",
        "    print(f\"KaggleHub failed: {e}\")\n",
        "    print(\"Please download creditcard.csv manually from https://www.kaggle.com/mlg-ulb/creditcardfraud\")\n",
        "    print(\"and place it in the ../data/ directory\")\n",
        "    # For now, let's assume you have the file\n",
        "    if os.path.exists(\"../data/creditcard.csv\"):\n",
        "        df = pd.read_csv(\"../data/creditcard.csv\")\n",
        "        print(\"Using existing dataset file\")\n",
        "    else:\n",
        "        raise FileNotFoundError(\"Please download the dataset first\")\n",
        "\n",
        "# Save to data directory\n",
        "os.makedirs(\"../data\", exist_ok=True)\n",
        "df.to_csv(\"../data/creditcard.csv\", index=False)\n",
        "print(f\"Dataset saved to ../data/creditcard.csv\")\n",
        "print(f\"Dataset shape: {df.shape}\")\n",
        "print(f\"Fraud cases: {df['Class'].sum()}\")\n",
        "print(f\"Non-fraud cases: {len(df) - df['Class'].sum()}\")\n",
        "\n",
        "# Load and split the data\n",
        "(X_train,\n",
        " X_val,\n",
        " X_test,\n",
        " y_train,\n",
        " y_val,\n",
        " y_test,\n",
        " scaler,) = load_creditcard_data(\"../data/creditcard.csv\")\n",
        "\n",
        "models = build_models()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Model: log_reg ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\hariv\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'accuracy': 0.9767213229872547, 'precision': 0.06017191977077364, 'recall': 0.8571428571428571, 'f1': 0.11244979919678715, 'roc_auc': 0.9614342993809791, 'pr_auc': -0.6692184044877432}\n",
            "\n",
            "=== Model: decision_tree ===\n",
            "{'accuracy': 0.9989817773252344, 'precision': 0.7272727272727273, 'recall': 0.6530612244897959, 'f1': 0.6881720430107527, 'roc_auc': 0.8263195824193492, 'pr_auc': -0.690465420458348}\n",
            "\n",
            "=== Model: random_forest ===\n",
            "{'accuracy': 0.9994382219725431, 'precision': 0.9714285714285714, 'recall': 0.6938775510204082, 'f1': 0.8095238095238095, 'roc_auc': 0.9257074523675537, 'pr_auc': -0.7979883332294069}\n",
            "\n",
            "=== Model: grad_boost ===\n",
            "{'accuracy': 0.9989817773252344, 'precision': 0.8125, 'recall': 0.5306122448979592, 'f1': 0.6419753086419753, 'roc_auc': 0.8160749457351877, 'pr_auc': -0.6647934554190484}\n"
          ]
        }
      ],
      "source": [
        "results = {}\n",
        "\n",
        "for name, model in models.items():\n",
        "    print(f\"\\n=== Model: {name} ===\")\n",
        "    model.fit(X_train, y_train)\n",
        "    y_val_pred = model.predict(X_val)\n",
        "    y_val_proba = None\n",
        "    if hasattr(model, \"predict_proba\"):\n",
        "        y_val_proba = model.predict_proba(X_val)[:, 1]\n",
        "    elif hasattr(model, \"decision_function\"):\n",
        "        y_val_proba = model.decision_function(X_val)\n",
        "\n",
        "    metrics = evaluate_predictions(y_val, y_val_pred, y_val_proba)\n",
        "    results[name] = metrics\n",
        "    print(metrics)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best model: random_forest {'accuracy': 0.9994382219725431, 'precision': 0.9714285714285714, 'recall': 0.6938775510204082, 'f1': 0.8095238095238095, 'roc_auc': 0.9257074523675537, 'pr_auc': -0.7979883332294069}\n",
            "\n",
            "Test metrics:\n",
            "{'accuracy': 0.9995435553526912, 'precision': 0.9615384615384616, 'recall': 0.7653061224489796, 'f1': 0.8522727272727273, 'roc_auc': 0.9573048620123344, 'pr_auc': -0.8683508053012461}\n",
            "Confusion matrix:\n",
            "[[56861     3]\n",
            " [   23    75]]\n",
            "\n",
            "Classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9996    0.9999    0.9998     56864\n",
            "           1     0.9615    0.7653    0.8523        98\n",
            "\n",
            "    accuracy                         0.9995     56962\n",
            "   macro avg     0.9806    0.8826    0.9260     56962\n",
            "weighted avg     0.9995    0.9995    0.9995     56962\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# pick best model by F1\n",
        "best_name = max(results, key=lambda k: results[k].get(\"f1\", 0.0))\n",
        "print(\"Best model:\", best_name, results[best_name])\n",
        "\n",
        "best_model = models[best_name]\n",
        "# retrain on train+val\n",
        "import numpy as np\n",
        "\n",
        "X_train_val = np.vstack([X_train, X_val])\n",
        "y_train_val = np.concatenate([y_train, y_val])\n",
        "\n",
        "best_model.fit(X_train_val, y_train_val)\n",
        "\n",
        "y_test_pred = best_model.predict(X_test)\n",
        "y_test_proba = None\n",
        "if hasattr(best_model, \"predict_proba\"):\n",
        "    y_test_proba = best_model.predict_proba(X_test)[:, 1]\n",
        "elif hasattr(best_model, \"decision_function\"):\n",
        "    y_test_proba = best_model.decision_function(X_test)\n",
        "\n",
        "print(\"\\nTest metrics:\")\n",
        "print(evaluate_predictions(y_test, y_test_pred, y_test_proba))\n",
        "print_detailed_report(y_test, y_test_pred)\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
